{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihoods templeates\n",
    "\n",
    "## Gaussian likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta, norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normal_lklhd(params,data):\n",
    "    model = data[\"model\"]\n",
    "    m = model(params, data)\n",
    "    ll= []\n",
    "    for idx, _ in enumerate(data[\"tr\"]):\n",
    "        p = norm.cdf([data[\"y\"][idx]-0.01, data[\"y\"][idx]+0.01], m[\"yhat\"][idx], 0.2) # assumes gauss SD 0.2\n",
    "        lklhd = -np.log(p[1]-p[0])\n",
    "\n",
    "        ll.append(lklhd)\n",
    "    \n",
    "    return np.sum(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01587624 0.11731043 0.86681333]\n"
     ]
    }
   ],
   "source": [
    "def softmax(values, temp, parametrization=\"inverse\"):\n",
    "    values = np.array(values)\n",
    "    \n",
    "    if parametrization == \"inverse\":\n",
    "        exponentiated = np.exp(values / temp)\n",
    "    elif parametrization == \"log_inverse\":\n",
    "        exponentiated = np.exp(values / np.log(temp))\n",
    "    elif parametrization == \"normal\":\n",
    "        exponentiated = np.exp(values * temp)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown parametrization: choose 'inverse', 'log_inverse', or 'normal'\")\n",
    "    \n",
    "    denom = np.sum(exponentiated)\n",
    "    probs = exponentiated / denom\n",
    "    return probs\n",
    "\n",
    "values = [1.0, 2.0, 3.0]\n",
    "temp = 0.5\n",
    "print(softmax(values, temp, parametrization=\"inverse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': array([-0.2416299 ,  0.78758155, -1.46310415,  0.38296659, -0.85721784,\n",
       "         0.48365558, -1.60250804, -1.48085888, -1.69308422, -1.04090002])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "data[\"y\"] = np.random.normal(0, 1, 10) # some data where each value corresponds to prediction on one trial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "General form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name(params, data):\n",
    "    parameter1 = params[0]\n",
    "    parameter2 = params[1]\n",
    "\n",
    "    ## model does something and generates predictions for each trial\n",
    "    pred =  [] \n",
    "\n",
    "    dataout = {\"yhat\": pred}\n",
    "    return dataout\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bee_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
